{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to IBM Db2 Event Store API\n",
    "\n",
    "\n",
    "> Note: This notebook runs with Scala 2.11 with Spark 2.3.2 kernel (shown as Default Spark Scala 2.11 kernel in IBM Cloud Pak for Data)\n",
    "\n",
    "IBM Db2 Event Store is a hybrid transactional/analytical processing (HTAP) system. It extends the Spark SQL interface to support transactions and accelerate analytics queries. This notebook includes examples of using the Scala client interface to create a database and a table. It also shows how to insert and query data in IBM Db2 Event Store by using Spark SQL.\n",
    "\n",
    "When you finish this demo, you will know how to manage and query data using IBM Db2 Event Store.    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "1. [Define a database](#define-database)<br>\n",
    "   1.1 [Open an existing database](#open-existing-db)<br>\n",
    "2. [Create your table](#create-table)<br>\n",
    "   2.1 [Define a schema for the table](#define-schema)<br>\n",
    "   2.2 [Create the table](#create-table-two)<br>\n",
    "   2.3 [Get a schema reference for the resolved table](#schema-reference)<br>\n",
    "3. [Generate and insert data rows](#generate-insert-data)<br>\n",
    "4. [Query the table](#query-table)<br>\n",
    "   4.1 [Create sqlContext using EventSession](#create-sqlContext)<br>\n",
    "   4.2 [Prepare a DataFrame for the query](#prepare-DataFrame)<br>\n",
    "   4.3 [Run the SQL query](#run-query)<br>\n",
    "5. [Drop the table](#drop-table)<br>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import com.ibm.event.common.ConfigurationReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"connect-to-es\"></a>\n",
    "### 1. Set up connection to IBM Db2 Event Store\n",
    "\n",
    "To establish a connection to IBM Db2 Event Store, you need to set the connection endpoints. Use the configuration reader to provide a set of APIs for IBM Db2 Event Store connection and configuration. The configurations need to be set differently, depending on whether the IBM Db2 Event Store is installed with Watson Studio Local (WSL) or IBM Cloud Pak for Data (CP4D).\n",
    "\n",
    "For more details on setting up IBM Db2 Event Store connection in Jupyter Notebook, please read the official documentation:\n",
    "https://www.ibm.com/support/knowledgecenter/en/SSGNPV_2.0.0/dsx/jupyter_prereq.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For IBM Db2 Event Store installed with Watson Studio Local (WSL)\n",
    "If your IBM Db2 Event Store is installed with Watson Studio Local (WSL), you will need to set the userID and password that will be used to connect to IBM Db2 Event Store instance.\n",
    "\n",
    "By default, the connection will be estabilished to the IBM Db2 Event Store instance on the current Watson Studio Local cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Using the configuration reader API, set up the userID and password that \n",
    "// will be used to connect to IBM Db2 Event Store.\n",
    "\n",
    "ConfigurationReader.setEventUser(\"<userid>\")\n",
    "ConfigurationReader.setEventPassword(\"<password>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For IBM Db2 Event Store installed with IBM Cloud Pak for Data (CP4D)\n",
    "If your IBM Db2 Event Store is installed with IBM Cloud Pak for Data (CP4D), you will need to:\n",
    "1. Set the deployment ID of the target IBM Db2 Event Store instance.\n",
    "2. Set the userID and password that will be used to connect to IBM Db2 Event Store instance.\n",
    "3. Set the connection endpoint of the target IBM Db2 Event Store instance. The connection endpoint is in the format of `<JDBC_CONNECTION_ENDPOINT>;<SCALA_CONNECTION_ENDPOINT>`. You can find the `<JDBC_CONNECTION_ENDPOINT>` and `<SCALA_CONNECTION_ENDPOINT>` in the **Database details** page of the target IBM Db2 Event Store instance in the IBM Cloud Pak for Data UI console.  \n",
    "\n",
    "For more details on setting up IBM Db2 Event Store connection in Jupyter Notebook, please read the official documentation: https://www.ibm.com/support/knowledgecenter/en/SSGNPV_2.0.0/dsx/jupyter_prereq.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/* Note: Only run this cell if your IBM Db2 Event Store is installed with IBM Cloud Pak for Data (CP4D) */\n",
    "\n",
    "// Use the configuration reader API to set up the deploymentID, userID, password, and connection endpoint that \n",
    "// will be used to connect to IBM Db2 Event Store.\n",
    "ConfigurationReader.setDeploymentID(\"<deploymentID>\")\n",
    "ConfigurationReader.setConnectionEndpoints(\"<JDBC_CONNECTION_ENDPOINT>;<SCALA_CONNECTION_ENDPOINT>\")\n",
    "ConfigurationReader.setEventUser(\"<userid>\")\n",
    "ConfigurationReader.setEventPassword(\"<password>\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"define-database\"></a>\n",
    "## 1. Define a database  \n",
    "Only one database can be concurrently active in IBM Db2 Event Store. If you already have a database, you don't need to create one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"open-existing-db\"></a>\n",
    "###  1.1 Open an existing database\n",
    "To use an existing database, use the following call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import com.ibm.event.oltp.EventContext\n",
    "val eContext = EventContext.getEventContext(\"EVENTDB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create-table\"></a>\n",
    "## 2. Create your table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"define-schema\"></a>\n",
    "### 2.1 Define a schema for the table\n",
    "To create a new table, you must first specify a schema for the table.\n",
    "Specify the columns, sharding key, and primary key, as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.types._\n",
    "import com.ibm.event.catalog.TableSchema\n",
    "val reviewSchema = TableSchema(\"ReviewTable\", \n",
    "       StructType(Array(\n",
    "          StructField(\"userId\", LongType, nullable = false),\n",
    "          StructField(\"categoryId\", IntegerType, nullable = false),\n",
    "          StructField(\"productName\", StringType, nullable = false),\n",
    "          StructField(\"boolfield\", BooleanType, nullable = false),\n",
    "          StructField(\"boolfield2\", BooleanType, nullable = true),\n",
    "          StructField(\"duration\", IntegerType, nullable = false ),\n",
    "          StructField(\"review\", StringType, nullable = false))),\n",
    "        shardingColumns = Seq(\"userId\"), pkColumns = Seq(\"userId\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Tip:</b> Databases in IBM Db2 Event Store are partitioned into shards. Any IBM Db2 Event Store node of a multi-node IBM Db2 Event Store cluster contains 0, 1 or N shards of the defined database. In addition to the mandatory shard key, there is also the option to provide a primary key. When this key is defined, IBM Db2 Event Store ensures that only a single version of each primary key exists in the database.\n",
    "\n",
    "In the above example, a sharding key and a primary key are defined on some columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create-table-two\"></a>\n",
    "### 2.2 Create the table\n",
    "Create the IBM Db2 Event Store table based on the above, unresolved schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eContext.createTable(reviewSchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"schema-reference\"></a>\n",
    "### 2.3 Get a schema reference for the resolved table\n",
    "To perform insert operations, a reference to the resolved table is needed. \n",
    "\n",
    "A resolved table contains additional metadata that is maintained and used by the IBM Db2 Event Store engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val reviewTable = eContext.getTable(\"ReviewTable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"generate-insert-data\"></a>\n",
    "## 3. Generate and insert data rows \n",
    "You can insert single-rows of data or perform batch inserts to insert multiple rows of data.\n",
    "A single row insert can be synchronous or asynchronous. Batch inserts are always performed asynchronously.  \n",
    "\n",
    "In the example below, random data is generated using a data generator. The data is then sent to the IBM Db2 Event Store engine in a batch, asynchronously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys.process._\n",
    "import scala.concurrent.{Await, Future}\n",
    "import scala.concurrent.duration.Duration\n",
    "import com.ibm.event.example.DataGenerator\n",
    "import com.ibm.event.oltp.InsertResult\n",
    "\n",
    "/** Insert generated rows asynchronously in batch */\n",
    "val numRowsPerBatch = 1000\n",
    "val numBatches = 1000\n",
    "var failCount = 0\n",
    "val startTime = System.currentTimeMillis()\n",
    "for {i <-1 to numBatches} {\n",
    "    val batch = DataGenerator.generateRows(reviewSchema.schema, numRowsPerBatch, 0, false).toIndexedSeq\n",
    "    val future: Future[InsertResult] = eContext.batchInsertAsync(reviewTable, batch)\n",
    "    val result: InsertResult = Await.result(future, Duration.Inf)\n",
    "    \n",
    "    if (result.failed) {\n",
    "        println(s\"batch insert incomplete: $result\") \n",
    "        failCount += numRowsPerBatch \n",
    "    }\n",
    "    else if (i % 100 == 0) { \n",
    "        System.out.println(s\"First $i batches successfully inserted\")\n",
    "    }\n",
    "}\n",
    "val numRowsInserted = numBatches*numRowsPerBatch\n",
    "println(s\"Ingested $numRowsInserted rows\")\n",
    "val timeInserting = (System.currentTimeMillis()-startTime)/1000.0\n",
    "println(s\"Ingest took $timeInserting seconds - ${(numRowsInserted -failCount)/timeInserting} inserts per second. $failCount inserts failed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asynchronous `batchInsert` API is provided on `EventContext` instance. \n",
    "The rows are supplied as an `IndexSeq[Row]`, where `Row` is Spark SQL row object that matches the `StructType` of the resolved table schema. The caller can immediately submit new inserts or wait for the operation to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"query-table\"></a>\n",
    "## 4. Query the table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create-sqlContext\"></a>\n",
    "### 4.1 Create sqlContext using EventSession\n",
    "\n",
    "To run a Spark SQL query, you need to establish an IBM Db2 Event Store Spark session using sqlContext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.io.File\n",
    "import com.ibm.event.oltp.EventContext\n",
    "import org.apache.log4j.{Level, LogManager, Logger}\n",
    "import org.apache.spark._\n",
    "import org.apache.spark.sql.ibm.event.EventSession\n",
    "\n",
    "val sqlContext = new EventSession(spark.sparkContext, \"EVENTDB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"prepare-DataFrame\"></a>\n",
    "### 4.2 Prepare a DataFrame for the query \n",
    "The following API provides a DataFrame that holds the query results on the IBM Db2 Event Store table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val table = sqlContext.loadEventTable(\"ReviewTable\")\n",
    "table.registerTempTable(\"ReviewTable\")\n",
    "val resultSet = sqlContext.sql(\"select count(*) as totalRows from ReviewTable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"run-query\"></a>\n",
    "### 4.3 Run the SQL query\n",
    "Now you can materialize the dataframe associated with the sql query by using either show() or pretty print %%dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultSet.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%dataframe resultSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"drop-table\"></a>\n",
    "## 5. Drop the table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eContext.dropTable(\"reviewTable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "## Summary\n",
    "This demo introduced you to the IBM Db2 Event Store API for managing and querying data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "* [IBM Db2 Event Store documentation](https://www.ibm.com/support/knowledgecenter/SSGNPV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Copyright &copy; IBM Corp. 2017. Released as licensed Sample Materials."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Scala 2.11 with Watson Studio Spark 2.0.2",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
