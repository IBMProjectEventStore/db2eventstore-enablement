{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBM Db2 Event Store with Machine Learning & Model Deployment using Python API \n",
    "\n",
    "IBM Db2 Event Store is a hybrid transactional/analytical processing (HTAP) system. It extends the Spark SQL interface to support transactions and accelerate analytics queries. This notebook includes examples of using the Scala client interface to create a database and a table. It also shows how to insert and query data in IBM Db2 Event Store by using Spark SQL. This notebook shows how to build and deploy machine learning model using IBM Db2 Event Store.\n",
    "\n",
    "When you finish this demo, you will know how to use Machine Learning and Model Deployment using IBM Db2 Event Store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "1. [Connect to IBM Db2 Event Store](#connect-to-es)<br>\n",
    "2. [Create a database and schema](#define-database)<br>\n",
    "3. [Generate rows & insert data into Event Store table](#generate-insert-data)<br>\n",
    "4. [Setup Spark Context](#setup-spark)<br>\n",
    "5. [Open Database](#open-database)<br>\n",
    "6. [Get table list from IBM Db2 Event Store ](#get-table-list)<br>\n",
    "7. [Load IBM Db2 Event Store table](#load-table)<br>\n",
    "8. [Run query on product table](#run-query)<br>\n",
    "9. [Build Model](#build-model)<br>\n",
    "10. [Save Model](#save-model)<br>\n",
    "11. [Make a prediction](#make-prediction)<br>\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eventstore.oltp import EventContext\n",
    "from eventstore.oltp.row_generator import generate_tele\n",
    "from eventstore.catalog import TableSchema, IndexSpecification, SortSpecification, ColumnOrder\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from eventstore.common import ConfigurationReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"connect-to-es\"></a>\n",
    "### 1. Set up connection to IBM Db2 Event Store\n",
    "\n",
    "To establish a connection to IBM Db2 Event Store, you need to set the connection endpoints. Use the configuration reader to provide a set of APIs for IBM Db2 Event Store connection and configuration. The configurations need to be set differently, depending on whether the IBM Db2 Event Store is installed with Watson Studio Local (WSL) or IBM Cloud Private for Data (ICP4D).\n",
    "\n",
    "For more details on setting up IBM Db2 Event Store connection in Jupyter Notebook, please read the official documentation:\n",
    "https://www.ibm.com/support/knowledgecenter/en/SSGNPV_2.0.0/dsx/jupyter_prereq.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### For IBM Db2 Event Store installed with Watson Studio Local (WSL)\n",
    "If your IBM Db2 Event Store is installed with Watson Studio Local (WSL), you will need to set the userID and password that will be used to connect to IBM Db2 Event Store instance.\n",
    "\n",
    "By default, the connection will be estabilished to the IBM Db2 Event Store instance on the current Watson Studio Local cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the configuration reader API, set up the userID and password that \n",
    "# will be used to connect to IBM Db2 Event Store.\n",
    "\n",
    "ConfigurationReader.setEventUser(\"<userid>\")\n",
    "ConfigurationReader.setEventPassword(\"<password>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For IBM Db2 Event Store installed with IBM Cloud Private for Data (ICP4D)\n",
    "If your IBM Db2 Event Store is installed with IBM Cloud Private for Data (ICP4D), you will need to:\n",
    "1. Add connection from IBM Cloud Private for Data (ICP4D) to IBM Db2 Event Store.  \n",
    "For more details on adding connection, please read the official documentation:\n",
    "https://www.ibm.com/support/knowledgecenter/en/SSGNPV_2.0.0/dsx/connect_ICP4D.html\n",
    "\n",
    "2. Set the userID and password that will be used to connect to IBM Db2 Event Store instance.\n",
    "3. Set the connection endpoint of the target IBM Db2 Event Store instance. The connection endpoint is in the format of \"<JDBC_CONNECTION_ENDPOINT>;<SCALA_CONNECTION_ENDPOINT>\". You can find the <JDBC_CONNECTION_ENDPOINT> and <SCALA_CONNECTION_ENDPOINT> in the **Database details** page in the IBM Cloud Private for Data UI console.  \n",
    "\n",
    "For more details on setting up IBM Db2 Event Store connection in Jupyter Notebook, please read the official documentation: https://www.ibm.com/support/knowledgecenter/en/SSGNPV_2.0.0/dsx/jupyter_prereq.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: Only run this cell if your IBM Db2 Event Store is installed with IBM Cloud Private for Data (ICP4D)\n",
    "\n",
    "# Using the configuration reader API, set up the userID, password and connection endpoint that \n",
    "# will be used to connect to IBM Db2 Event Store.\n",
    "ConfigurationReader.setConnectionEndpoints(\"<JDBC_CONNECTION_ENDPOINT>;<SCALA_CONNECTION_ENDPOINT>\")\n",
    "ConfigurationReader.setEventUser(\"<userid>\")\n",
    "ConfigurationReader.setEventPassword(\"<password>\")\n",
    "\n",
    "# Do not change the following configurations.\n",
    "ConfigurationReader.setSslKeyStoreLocation(\"/user-home/_global_/security/customer-truststores/cacerts\")\n",
    "ConfigurationReader.setSslKeyStorePassword(\"changeit\")\n",
    "ConfigurationReader.setSslTrustStoreLocation(\"/user-home/_global_/security/customer-truststores/cacerts\")\n",
    "ConfigurationReader.setSslTrustStorePassword(\"changeit\")\n",
    "ConfigurationReader.setClientPluginName(\"IBMIAMauth\")\n",
    "ConfigurationReader.setClientPlugin(True)\n",
    "ConfigurationReader.setSSLEnabled(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"define-database\"></a>\n",
    "### 2. Connect to a database and schema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with EventContext.get_event_context(\"EVENTDB\") as ctx:\n",
    "    \n",
    "    schema = StructType([\n",
    "        StructField(\"PRODUCT_ID\", IntegerType(), nullable=False),\n",
    "        StructField(\"PRODUCT_CODE\", IntegerType(), nullable=False),\n",
    "        StructField(\"PRODUCT_DEPT\", IntegerType(), nullable=True),\n",
    "        StructField(\"PRODUCT_LINE\", StringType(), nullable=True),\n",
    "        StructField(\"GENDER\", StringType(), nullable=True),\n",
    "        StructField(\"AGE\", IntegerType(), nullable=False),\n",
    "        StructField(\"MARITAL_STATUS\", StringType(), nullable=True),\n",
    "        StructField(\"PROFESSION\", StringType(), nullable=True)\n",
    "    ])\n",
    "    table_name = \"product\"\n",
    "    table_schema = TableSchema(table_name, schema,\n",
    "                              sharding_columns=[\"PRODUCT_ID\"],\n",
    "                              pk_columns=[\"PRODUCT_ID\", \"PRODUCT_CODE\", \"AGE\"])\n",
    "    index_spec = IndexSpecification(index_name=\"productidx\",\n",
    "                                    table_schema=table_schema,\n",
    "                                    equal_columns=[\"PRODUCT_ID\", \"PRODUCT_CODE\"],\n",
    "                                    sort_columns=[SortSpecification(\"AGE\", ColumnOrder.ASCENDING_NULLS_LAST)],\n",
    "                                    include_columns=[\"PRODUCT_DEPT\"])\n",
    "\n",
    "    print(\"creating table with index...\\n{}\".format(table_schema))\n",
    "    ctx.create_table_with_index(table_schema, index_spec)\n",
    "    print(\"list of table names:\")\n",
    "    table_names = ctx.get_names_of_tables()\n",
    "    for idx, name in enumerate(table_names):\n",
    "        print(\"\\t{}: {}\".format(idx, name))\n",
    "\n",
    "    print(\"get table: \")\n",
    "    resolved_table_schema = ctx.get_table(table_name)\n",
    "    print(\"resolved table schema: {}\".format(resolved_table_schema))\n",
    "    print(\"JVM resolved table schema: {}\".format(resolved_table_schema.jresolved_table_schema))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"generate-insert-data\"></a>\n",
    "### 3. Generate rows & insert data into Event Store table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_batch = []\n",
    "for x in range(0, 10000, 2):\n",
    "    row_batch.append(dict(PRODUCT_ID=x, PRODUCT_CODE=1, PRODUCT_DEPT=50 , PRODUCT_LINE=\"Personal Accessories\" , GENDER=\"Male\", AGE=30, MARITAL_STATUS=\"Single\", PROFESSION=\"Hospitality\"))\n",
    "    row_batch.append(dict(PRODUCT_ID=x, PRODUCT_CODE=2, PRODUCT_DEPT=60 , PRODUCT_LINE=\"Camping Equipment\" , GENDER=\"Female\", AGE=40, MARITAL_STATUS=\"Single\", PROFESSION=\"Sales\"))\n",
    "    row_batch.append(dict(PRODUCT_ID=x, PRODUCT_CODE=3, PRODUCT_DEPT=70 , PRODUCT_LINE=\"Golf Equipment\" , GENDER=\"Male\", AGE=35, MARITAL_STATUS=\"Married\", PROFESSION=\"Retail\"))\n",
    "    row_batch.append(dict(PRODUCT_ID=x, PRODUCT_CODE=4, PRODUCT_DEPT=80 , PRODUCT_LINE=\"Mountaineering Eq\" , GENDER=\"Female\", AGE=45, MARITAL_STATUS=\"Married\", PROFESSION=\"Engineer\"))\n",
    "print(len(row_batch))\n",
    "ctx.batch_insert(resolved_table_schema, row_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from eventstore.sql import EventSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup-spark\"></a>\n",
    "### 4. Setup Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sparkSession = SparkSession.builder.appName(\"Event Store ML in Python\").getOrCreate()\n",
    "\n",
    "eventSession = EventSession(sparkSession.sparkContext, \"EVENTDB\")\n",
    "eventSession.set_query_read_option(\"SnapshotNow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"open-database\"></a>\n",
    "### 5. Open Database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eventSession.open_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get-table-list\"></a>\n",
    "### 6. Get table list from IBM Db2 Event Store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with EventContext.get_event_context(\"EVENTDB\") as ctx:\n",
    "    print(\"tables: \")\n",
    "    table_names = ctx.get_names_of_tables()\n",
    "    for idx, name in enumerate(table_names):\n",
    "        print(\"\\t{}: {}\".format(idx, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load-table\"></a>\n",
    "### 7. Load IBM Db2 Event Store table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = eventSession.load_event_table(\"product\")\n",
    "print(\"product table {}: {}\".format(type(product), product))\n",
    "product.createOrReplaceTempView(\"product\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"run-query\"></a>\n",
    "### 8. Run query on product table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT PRODUCT_LINE, GENDER, AGE, MARITAL_STATUS, PROFESSION FROM product\"\n",
    "print(\"{}\\nRunning query in Event Store...\".format(query))\n",
    "df_data = eventSession.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.printSchema()\n",
    "df_data.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"build-model\"></a>\n",
    "### 9. Build Model \n",
    "In the model training process, the original dataset will be split into training dataset and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_data = df_data.randomSplit([0.8, 0.18, 0.02], 24)\n",
    "train_data = splitted_data[0]\n",
    "test_data = splitted_data[1]\n",
    "predict_data = splitted_data[2]\n",
    "\n",
    "print(\"Number of training records: \" + str(train_data.count()))\n",
    "print(\"Number of testing records : \" + str(test_data.count()))\n",
    "print(\"Number of prediction records : \" + str(predict_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, IndexToString, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stringIndexer_label = StringIndexer(inputCol=\"PRODUCT_LINE\", outputCol=\"label\").fit(df_data)\n",
    "stringIndexer_prof = StringIndexer(inputCol=\"PROFESSION\", outputCol=\"PROFESSION_IX\")\n",
    "stringIndexer_gend = StringIndexer(inputCol=\"GENDER\", outputCol=\"GENDER_IX\")\n",
    "stringIndexer_mar = StringIndexer(inputCol=\"MARITAL_STATUS\", outputCol=\"MARITAL_STATUS_IX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following task is to set the input columns for model training, and use the corresponding algorithms to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorAssembler_features = VectorAssembler(inputCols=[\"GENDER_IX\", \"AGE\", \"MARITAL_STATUS_IX\", \"PROFESSION_IX\"], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=stringIndexer_label.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_rf = Pipeline(stages=[stringIndexer_label, stringIndexer_prof, stringIndexer_gend, stringIndexer_mar, vectorAssembler_features, rf, labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = pipeline_rf.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_rf.transform(test_data)\n",
    "evaluatorRF = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluatorRF.evaluate(predictions)\n",
    "print(\"Accuracy = %g\" % accuracy)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"save-model\"></a>\n",
    "### 10. Save Model\n",
    "\n",
    "After the model is successfully trained, repository service is used to save the model. The model name and author information can be customized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsx_ml.ml import save\n",
    "model_name = \"Event Store Product Line Prediction Model\"\n",
    "saved_model = save(name=model_name, model=model_rf, test_data=train_data,algorithm_type='Classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "header_online = {'Content-Type': 'application/json', 'Authorization': os.environ['DSX_TOKEN']}\n",
    "\n",
    "print(saved_model['scoring_endpoint'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_rf.transform(predict_data)\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.select(\"predictedLabel\").groupBy(\"predictedLabel\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas\n",
    "import plotly.plotly as py\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import cufflinks as cf\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "sys.path.append(\"\".join([os.environ[\"HOME\"]])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_pdf = predictions.select(\"prediction\", \"predictedLabel\", \"GENDER\", \"AGE\", \"PROFESSION\", \"MARITAL_STATUS\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_stats = predictions_pdf.groupby(['predictedLabel']).count()\n",
    "\n",
    "product_data = [go.Pie(\n",
    "            labels=cumulative_stats.index,\n",
    "            values=cumulative_stats['GENDER'],\n",
    "    )]\n",
    "\n",
    "product_layout = go.Layout(\n",
    "    title='Predicted product line client interest distribution',\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=product_data, layout=product_layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "age_data = [go.Bar(\n",
    "            y=predictions_pdf.groupby(['predictedLabel']).mean()[\"AGE\"],\n",
    "            x=cumulative_stats.index\n",
    "            \n",
    "    )]\n",
    "\n",
    "age_layout = go.Layout(\n",
    "    title='Mean AGE per predicted product line',\n",
    "    xaxis=dict(\n",
    "        title = \"Product Line\",\n",
    "        showline=False,),\n",
    "    yaxis=dict(\n",
    "        title = \"Mean AGE\",\n",
    "        ),\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=age_data, layout=age_layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"make-prediction\"></a>\n",
    "### 11. Make a prediction\n",
    "\n",
    "After deployment, the endpoint of model can be used to give prediction for new data using the online scoring service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = { \"GENDER\" : \"Female\", \"AGE\" : 30, \"MARITAL_STATUS\" : \"Married\", \"PROFESSION\" : \"Engineer\" }\n",
    "payload_scoring = [new_data]\n",
    "scoring_response = requests.post(saved_model['scoring_endpoint'], json=payload_scoring, headers=header_online, verify=False)\n",
    "\n",
    "print(scoring_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = { \"GENDER\" : \"Male\", \"AGE\" : 30, \"MARITAL_STATUS\" : \"Married\", \"PROFESSION\" : \"Engineer\" }\n",
    "payload_scoring = [new_data]\n",
    "scoring_response = requests.post(saved_model['scoring_endpoint'], json=payload_scoring, headers=header_online, verify=False)\n",
    "\n",
    "print(scoring_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "## Summary\n",
    "This demo introduced you to the IBM Db2 Event Store API for Machine Learning and Model Deployment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Copyright &copy; IBM Corp. 2017. Released as licensed Sample Materials."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
